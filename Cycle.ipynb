{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab4e461",
      "metadata": {
        "id": "9ab4e461"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1e19af",
      "metadata": {
        "id": "3b1e19af"
      },
      "outputs": [],
      "source": [
        "from random import random\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate,Dropout\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization \n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973a59a1",
      "metadata": {
        "id": "973a59a1"
      },
      "outputs": [],
      "source": [
        "# discriminator model (70x70 patchGAN)\n",
        "# C64-C128-C256-C512\n",
        "#After the last layer, conv to 1-dimensional output, followed by a Sigmoid function.  \n",
        "# The “axis” argument is set to -1 for instance norm. to ensure that features are normalized per feature map.\n",
        "def define_discriminator(image_shape):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # source image input\n",
        "    in_image = Input(shape=image_shape)\n",
        "    # C64: 4x4 kernel Stride 2x2\n",
        "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C128: 4x4 kernel Stride 2x2\n",
        "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = InstanceNormalization(axis=-1)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C256: 4x4 kernel Stride 2x2\n",
        "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = InstanceNormalization(axis=-1)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # C512: 4x4 kernel Stride 2x2 \n",
        "    # Not in the original paper. Comment this block if you want.\n",
        "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "    d = InstanceNormalization(axis=-1)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # second last output layer : 4x4 kernel but Stride 1x1\n",
        "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "    d = InstanceNormalization(axis=-1)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    # patch output\n",
        "    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "    # define model\n",
        "    model = Model(in_image, patch_out)\n",
        "    # compile model\n",
        "    #The model is trained with a batch size of one image and Adam opt. \n",
        "    #with a small learning rate and 0.5 beta. \n",
        "    #The loss for the discriminator is weighted by 50% for each model update.\n",
        "    #This slows down changes to the discriminator relative to the generator model during training.\n",
        "    model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ade743",
      "metadata": {
        "id": "66ade743"
      },
      "outputs": [],
      "source": [
        "# generator a resnet block to be used in the generator\n",
        "# residual block that contains two 3 × 3 convolutional layers with the same number of filters on both layers.\n",
        "def resnet_block(n_filters, input_layer):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # first convolutional layer\n",
        "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # second convolutional layer\n",
        "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    # concatenate merge channel-wise with input layer\n",
        "    g = Concatenate()([g, input_layer])\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349a3c7e",
      "metadata": {
        "id": "349a3c7e"
      },
      "outputs": [],
      "source": [
        "# define the  generator model - encoder-decoder type architecture\n",
        "\n",
        "#c7s1-k denote a 7×7 Convolution-InstanceNorm-ReLU layer with k filters and stride 1. \n",
        "#dk denotes a 3 × 3 Convolution-InstanceNorm-ReLU layer with k filters and stride 2.\n",
        "# Rk denotes a residual block that contains two 3 × 3 convolutional layers\n",
        "# uk denotes a 3 × 3 fractional-strided-Convolution InstanceNorm-ReLU layer with k filters and stride 1/2\n",
        "\n",
        "#The network with 6 residual blocks consists of:\n",
        "#c7s1-64,d128,d256,R256,R256,R256,R256,R256,R256,u128,u64,c7s1-3\n",
        "\n",
        "#The network with 9 residual blocks consists of:\n",
        "#c7s1-64,d128,d256,R256,R256,R256,R256,R256,R256,R256,R256,R256,u128, u64,c7s1-3\n",
        "\n",
        "def define_generator(image_shape, n_resnet=9):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # image input\n",
        "    in_image = Input(shape=image_shape)\n",
        "    # c7s1-64\n",
        "    g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # d128\n",
        "    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # d256\n",
        "    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # R256\n",
        "    for _ in range(n_resnet):\n",
        "        g = resnet_block(256, g)\n",
        "    # u128\n",
        "    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # u64\n",
        "    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    g = Activation('relu')(g)\n",
        "    # c7s1-3\n",
        "    g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "    g = InstanceNormalization(axis=-1)(g)\n",
        "    out_image = Activation('tanh')(g)\n",
        "    # define model\n",
        "    model = Model(in_image, out_image)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671003a5",
      "metadata": {
        "id": "671003a5"
      },
      "outputs": [],
      "source": [
        "# define a composite model for updating generators by adversarial and cycle loss\n",
        "#We define a composite model that will be used to train each generator separately. \n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "    # Make the generator of interest trainable as we will be updating these weights.\n",
        "    #by keeping other models constant.\n",
        "    #Remember that we use this same function to train both generators,\n",
        "    #one generator at a time. \n",
        "    g_model_1.trainable = True\n",
        "    # mark discriminator and second generator as non-trainable\n",
        "    d_model.trainable = False\n",
        "    g_model_2.trainable = False\n",
        "\n",
        "    # adversarial loss\n",
        "    input_gen = Input(shape=image_shape)\n",
        "    gen1_out = g_model_1(input_gen)\n",
        "    output_d = d_model(gen1_out)\n",
        "    # identity loss\n",
        "    input_id = Input(shape=image_shape)\n",
        "    output_id = g_model_1(input_id)\n",
        "    # cycle loss - forward\n",
        "    output_f = g_model_2(gen1_out)\n",
        "    # cycle loss - backward\n",
        "    gen2_out = g_model_2(input_id)\n",
        "    output_b = g_model_1(gen2_out)\n",
        "\n",
        "    # define model graph\n",
        "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\n",
        "    # define the optimizer\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    # compile model with weighting of least squares loss and L1 loss\n",
        "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], \n",
        "               loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93c37b9",
      "metadata": {
        "id": "e93c37b9"
      },
      "outputs": [],
      "source": [
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "    # load the dataset\n",
        "    data = load(filename)\n",
        "    # unpack arrays\n",
        "    X1, X2 = data['arr_0'], data['arr_1']\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X1 = (X1 - 127.5) / 127.5\n",
        "    X2 = (X2 - 127.5) / 127.5\n",
        "    return [X1, X2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a244989",
      "metadata": {
        "id": "6a244989"
      },
      "outputs": [],
      "source": [
        "# select a batch of random samples, returns images and target\n",
        "#Remember that for real images the label (y) is 1. \n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb84fcf",
      "metadata": {
        "id": "dfb84fcf"
      },
      "outputs": [],
      "source": [
        "# generate a batch of images, returns images and targets\n",
        "#Remember that for fake images the label (y) is 0. \n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "    # generate fake images\n",
        "    X = g_model.predict(dataset)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "418ac7fb",
      "metadata": {
        "id": "418ac7fb"
      },
      "outputs": [],
      "source": [
        "# periodically save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "    # save the first generator model\n",
        "    filename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
        "    g_model_AtoB.save(filename1)\n",
        "    # save the second generator model\n",
        "    filename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
        "    g_model_BtoA.save(filename2)\n",
        "    print('>Saved: %s and %s' % (filename1, filename2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d2a598",
      "metadata": {
        "id": "36d2a598"
      },
      "outputs": [],
      "source": [
        "# periodically generate images using the save model and plot input and output images\n",
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "    # select a sample of input images\n",
        "    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "    # generate translated images\n",
        "    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "    # scale all pixels from [-1,1] to [0,1]\n",
        "    X_in = (X_in + 1) / 2.0\n",
        "    X_out = (X_out + 1) / 2.0\n",
        "    # plot real images\n",
        "    for i in range(n_samples):\n",
        "        pyplot.subplot(2, n_samples, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(X_in[i])\n",
        "    # plot translated image\n",
        "    for i in range(n_samples):\n",
        "        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(X_out[i])\n",
        "    # save plot to file\n",
        "    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "    pyplot.savefig(filename1)\n",
        "    pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21200845",
      "metadata": {
        "id": "21200845"
      },
      "outputs": [],
      "source": [
        "# update image pool for fake images to reduce model oscillation\n",
        "# update discriminators using a history of generated images \n",
        "#rather than the ones produced by the latest generators.\n",
        "#Original paper recommended keeping an image buffer that stores \n",
        "#the 50 previously created images.\n",
        "\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "    selected = list()\n",
        "    for image in images:\n",
        "        if len(pool) < max_size:\n",
        "            # stock the pool\n",
        "            pool.append(image)\n",
        "            selected.append(image)\n",
        "        elif random() < 0.5:\n",
        "            # use image, but don't add it to the pool\n",
        "            selected.append(image)\n",
        "        else:\n",
        "            # replace an existing image and use replaced image\n",
        "            ix = randint(0, len(pool))\n",
        "            selected.append(pool[ix])\n",
        "            pool[ix] = image\n",
        "    return asarray(selected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65110612",
      "metadata": {
        "id": "65110612"
      },
      "outputs": [],
      "source": [
        "# train cyclegan models\n",
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=1):\n",
        "    # define properties of the training run\n",
        "    n_epochs, n_batch, = epochs, 1  #batch size fixed to 1 as suggested in the paper\n",
        "    # determine the output square shape of the discriminator\n",
        "    n_patch = d_model_A.output_shape[1]\n",
        "    # unpack dataset\n",
        "    trainA, trainB = dataset\n",
        "    # prepare image pool for fake images\n",
        "    poolA, poolB = list(), list()\n",
        "    # calculate the number of batches per training epoch\n",
        "    bat_per_epo = int(len(trainA) / n_batch)\n",
        "    # calculate the number of training iterations\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_steps):\n",
        "        # select a batch of real samples from each domain (A and B)\n",
        "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "        # generate a batch of fake samples using both B to A and A to B generators.\n",
        "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "        # update fake images in the pool. Remember that the paper suggstes a buffer of 50 images\n",
        "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\n",
        "        # update generator B->A via the composite model\n",
        "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "        # update discriminator for A -> [real/fake]\n",
        "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\n",
        "        # update generator A->B via the composite model\n",
        "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "        # update discriminator for B -> [real/fake]\n",
        "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\n",
        "        # summarize performance\n",
        "        #Since our batch size =1, the number of iterations would be same as the size of our dataset.\n",
        "        #In one epoch you'd have iterations equal to the number of images.\n",
        "        #If you have 100 images then 1 epoch would be 100 iterations\n",
        "        print('Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "        # evaluate the model performance periodically\n",
        "        #If batch size (total images)=100, performance will be summarized after every 75th iteration.\n",
        "        if (i+1) % (bat_per_epo * 1) == 0:\n",
        "            # plot A->B translation\n",
        "            summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
        "            # plot B->A translation\n",
        "            summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
        "        if (i+1) % (bat_per_epo * 1) == 0:\n",
        "            # save the models\n",
        "            # #If batch size (total images)=100, model will be saved after \n",
        "            #every 75th iteration x 5 = 375 iterations.\n",
        "            save_models(i, g_model_AtoB, g_model_BtoA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf3326f",
      "metadata": {
        "id": "bbf3326f"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "961ade5d",
      "metadata": {
        "id": "961ade5d"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0758b4d",
      "metadata": {
        "id": "f0758b4d"
      },
      "outputs": [],
      "source": [
        "Data_path_photos=r\"D:\\archive\\photos\"\n",
        "Data_path_sketches=r\"D:\\archive\\sketches\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d4a5f7",
      "metadata": {
        "id": "60d4a5f7"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "    photos=[]\n",
        "    photos_label=[]\n",
        "    \n",
        "    for file_name in os.listdir(Data_path_photos):\n",
        "        img_path=os.path.join(Data_path_photos,file_name)\n",
        "        \n",
        "        image=cv2.resize(cv2.imread(img_path),(IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        photos.append(np.array(image))\n",
        "        photos_label.append(file_name)\n",
        "        \n",
        "    photos=np.asarray(photos) \n",
        "    photos_label=np.asarray(photos_label)\n",
        "    sketches=[]\n",
        "    sketches_label=[]\n",
        "    \n",
        "    for file_name in os.listdir(Data_path_sketches):\n",
        "        img_path=os.path.join(Data_path_sketches,file_name)\n",
        "        \n",
        "        image=cv2.resize(cv2.imread(img_path),(IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        sketches.append(np.array(image))\n",
        "        sketches_label.append(file_name)\n",
        "        \n",
        "    sketches=np.asarray(sketches)\n",
        "    sketches_label=np.asarray(sketches_label)\n",
        "    return photos,photos_label,sketches,sketches_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f6453c",
      "metadata": {
        "id": "a3f6453c"
      },
      "outputs": [],
      "source": [
        "photos,photos_label,sketches,sketches_label=create_dataset()\n",
        "#photos=photos[:30]\n",
        "#sketches=sketches[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4510e0c",
      "metadata": {
        "id": "f4510e0c"
      },
      "outputs": [],
      "source": [
        "photos=photos[:100]\n",
        "sketches=sketches[:100]\n",
        "\n",
        "test_p=photos[101:]\n",
        "test_s=sketches[101:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461cede3",
      "metadata": {
        "id": "461cede3",
        "outputId": "092aa0c6-e10b-4622-978a-36a71f3fc473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "print(photos.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db4227a",
      "metadata": {
        "id": "2db4227a",
        "outputId": "a286d0d7-6db6-4978-b72c-b10c88213170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "print(sketches.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca75edea",
      "metadata": {
        "id": "ca75edea"
      },
      "outputs": [],
      "source": [
        "data = [photos, sketches]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a0954e",
      "metadata": {
        "id": "23a0954e",
        "outputId": "e1630823-2dbe-499c-e189-3a5da2f1023a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded (100, 256, 256, 3) (100, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "print('Loaded', data[0].shape, data[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3c2967",
      "metadata": {
        "id": "ce3c2967"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "    # load compressed arrays\n",
        "    # unpack arrays\n",
        "    X1, X2 = data[0], data[1]\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X1 = (X1 - 127.5) / 127.5\n",
        "    X2 = (X2 - 127.5) / 127.5\n",
        "    return [X1, X2]\n",
        "\n",
        "dataset = preprocess_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b11a76",
      "metadata": {
        "id": "15b11a76",
        "outputId": "b2d5aa3f-3e22-42e6-e6a9-d37697103cf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "Iteration>1, dA[1.369,0.739] dB[2.012,0.796] g[22.498,21.742]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>2, dA[7.146,1.185] dB[9.116,2.047] g[22.799,19.949]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>3, dA[6.908,1.155] dB[5.394,2.526] g[22.169,19.678]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>4, dA[8.657,0.922] dB[1.502,6.706] g[24.749,18.764]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>5, dA[7.692,0.746] dB[2.788,3.851] g[26.033,16.754]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>6, dA[2.217,0.655] dB[5.578,0.983] g[19.773,15.475]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>7, dA[1.207,0.569] dB[2.620,1.191] g[16.019,14.443]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>8, dA[0.475,0.759] dB[1.717,1.295] g[14.475,13.775]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>9, dA[1.097,0.420] dB[1.977,1.311] g[15.066,13.247]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>10, dA[0.450,0.449] dB[0.773,0.509] g[13.048,12.016]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>11, dA[0.198,0.535] dB[0.657,0.561] g[11.958,10.915]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>12, dA[0.343,0.393] dB[0.415,0.749] g[12.197,10.400]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>13, dA[0.331,0.291] dB[0.491,0.594] g[10.013,8.761]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>14, dA[0.178,0.200] dB[0.458,0.396] g[11.794,10.058]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>15, dA[0.166,0.260] dB[0.275,0.403] g[8.769,7.686]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>16, dA[0.366,0.256] dB[0.416,0.331] g[11.731,10.729]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>17, dA[0.203,0.232] dB[0.289,0.227] g[8.781,7.649]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>18, dA[0.216,0.199] dB[0.276,0.264] g[11.709,9.910]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>19, dA[0.192,0.235] dB[0.255,0.234] g[10.243,8.557]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>20, dA[0.286,0.223] dB[0.243,0.287] g[11.474,9.811]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>21, dA[0.211,0.276] dB[0.356,0.239] g[8.699,7.714]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>22, dA[0.200,0.190] dB[0.210,0.220] g[11.146,9.682]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Iteration>23, dA[0.205,0.266] dB[0.201,0.203] g[9.283,7.898]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>24, dA[0.267,0.192] dB[0.155,0.220] g[11.345,9.535]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>25, dA[0.211,0.216] dB[0.239,0.214] g[8.259,7.457]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>26, dA[0.263,0.206] dB[0.321,0.184] g[9.868,9.068]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>27, dA[0.198,0.160] dB[0.194,0.197] g[9.723,8.781]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>28, dA[0.456,0.396] dB[0.274,0.245] g[7.648,6.776]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>29, dA[0.276,0.188] dB[0.158,0.289] g[10.734,8.883]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>30, dA[0.191,0.165] dB[0.183,0.280] g[10.255,9.019]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>31, dA[0.163,0.227] dB[0.223,0.129] g[10.590,8.942]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>32, dA[0.247,0.148] dB[0.136,0.260] g[10.831,9.449]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>33, dA[0.216,0.190] dB[0.176,0.197] g[11.038,8.713]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>34, dA[0.128,0.255] dB[0.370,0.174] g[7.657,6.899]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>35, dA[0.250,0.364] dB[0.264,0.246] g[7.414,6.749]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>36, dA[0.282,0.246] dB[0.278,0.183] g[9.068,7.846]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>37, dA[0.242,0.201] dB[0.280,0.265] g[7.730,6.861]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>38, dA[0.160,0.175] dB[0.223,0.329] g[9.869,8.480]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>39, dA[0.178,0.155] dB[0.202,0.188] g[7.866,7.067]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>40, dA[0.163,0.212] dB[0.193,0.176] g[8.996,8.481]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>41, dA[0.194,0.224] dB[0.141,0.228] g[8.289,7.385]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>42, dA[0.164,0.194] dB[0.179,0.089] g[9.015,7.415]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>43, dA[0.188,0.394] dB[0.184,0.193] g[8.155,6.603]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>44, dA[0.139,0.220] dB[0.223,0.136] g[9.414,7.920]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>45, dA[0.417,0.584] dB[0.088,0.175] g[10.398,8.527]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>46, dA[0.418,0.350] dB[0.175,0.113] g[7.759,6.775]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>47, dA[0.221,0.208] dB[0.206,0.175] g[7.781,6.574]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>48, dA[0.237,0.197] dB[0.255,0.219] g[7.057,6.056]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>49, dA[0.210,0.138] dB[0.122,0.133] g[9.300,8.843]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>50, dA[0.136,0.235] dB[0.179,0.142] g[6.733,5.959]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>51, dA[0.090,0.182] dB[0.127,0.084] g[6.261,5.530]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>52, dA[0.182,0.182] dB[0.137,0.097] g[8.443,7.082]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>53, dA[0.214,0.390] dB[0.113,0.233] g[8.148,7.153]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>54, dA[0.399,0.352] dB[0.167,0.070] g[8.197,7.167]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>55, dA[0.256,0.234] dB[0.079,0.105] g[9.502,7.623]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>56, dA[0.260,0.137] dB[0.117,0.145] g[7.378,6.235]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>57, dA[0.219,0.194] dB[0.180,0.149] g[7.893,6.717]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>58, dA[0.143,0.090] dB[0.167,0.144] g[8.088,8.093]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>59, dA[0.109,0.222] dB[0.092,0.139] g[9.291,8.368]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>60, dA[0.249,0.064] dB[0.092,0.105] g[9.359,8.052]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>61, dA[0.101,0.167] dB[0.120,0.080] g[11.538,10.300]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>62, dA[0.118,0.637] dB[0.181,0.177] g[12.292,9.596]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>63, dA[0.290,0.274] dB[0.125,0.140] g[9.127,7.829]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>64, dA[0.237,0.273] dB[0.161,0.147] g[10.749,10.159]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>65, dA[0.237,0.168] dB[0.143,0.110] g[10.981,9.323]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>66, dA[0.227,0.293] dB[0.084,0.192] g[8.382,7.122]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>67, dA[0.257,0.220] dB[0.123,0.125] g[8.212,6.872]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>68, dA[0.207,0.150] dB[0.226,0.141] g[7.209,6.481]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>69, dA[0.099,0.100] dB[0.116,0.136] g[8.374,7.013]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>70, dA[0.069,0.147] dB[0.146,0.125] g[8.957,6.928]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>71, dA[0.199,0.155] dB[0.212,0.103] g[8.311,6.700]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>72, dA[0.110,0.145] dB[0.154,0.447] g[5.726,5.172]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>73, dA[0.148,0.147] dB[0.238,0.143] g[9.803,9.009]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>74, dA[0.142,0.055] dB[0.171,0.097] g[7.801,6.920]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>75, dA[0.145,0.373] dB[0.143,0.064] g[7.967,6.523]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>76, dA[0.084,0.137] dB[0.205,0.143] g[9.314,7.765]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>77, dA[0.131,0.183] dB[0.082,0.147] g[9.412,7.540]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>78, dA[0.245,1.080] dB[0.077,0.087] g[11.667,9.093]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>79, dA[0.140,0.195] dB[0.086,0.106] g[9.206,7.536]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>80, dA[0.135,0.161] dB[0.090,0.114] g[9.702,8.019]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>81, dA[0.188,0.102] dB[0.161,0.231] g[8.246,7.197]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>82, dA[0.142,0.274] dB[0.217,0.157] g[8.153,6.550]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>83, dA[0.086,0.052] dB[0.176,0.155] g[8.439,6.823]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>84, dA[0.117,0.242] dB[0.082,0.044] g[8.452,6.765]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>85, dA[0.100,0.145] dB[0.047,0.116] g[9.335,7.438]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>86, dA[0.133,0.130] dB[0.080,0.093] g[7.423,6.102]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>87, dA[0.267,0.164] dB[0.062,0.063] g[9.614,8.562]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>88, dA[0.222,0.131] dB[0.034,0.208] g[7.919,6.599]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>89, dA[0.152,0.231] dB[0.165,0.087] g[7.072,6.012]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>90, dA[0.270,0.113] dB[0.088,0.055] g[9.411,7.774]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>91, dA[0.111,0.108] dB[0.088,0.069] g[8.343,6.947]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>92, dA[0.138,0.144] dB[0.049,0.315] g[8.805,7.374]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>93, dA[0.143,0.212] dB[0.194,0.118] g[10.393,9.011]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>94, dA[0.147,0.262] dB[0.304,0.146] g[7.663,6.204]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>95, dA[0.163,0.263] dB[0.060,0.105] g[9.808,8.310]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>96, dA[0.167,0.295] dB[0.181,0.146] g[7.712,6.463]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>97, dA[0.091,0.070] dB[0.234,0.105] g[8.335,7.056]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>98, dA[0.132,0.054] dB[0.088,0.303] g[10.715,9.198]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>99, dA[0.062,0.241] dB[0.120,0.090] g[8.655,6.840]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Iteration>100, dA[0.079,0.197] dB[0.300,0.104] g[7.592,5.845]\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">Saved: g_model_AtoB_000100.h5 and g_model_BtoA_000100.h5\n",
            "Execution time is:  1:47:17.563339\n"
          ]
        }
      ],
      "source": [
        "image_shape = dataset[0].shape[1:]\n",
        "# generator: A -> B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "# generator: B -> A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "# discriminator: A -> [real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "# discriminator: B -> [real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
        "\n",
        "from datetime import datetime \n",
        "start1 = datetime.now() \n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=1)\n",
        "\n",
        "stop1 = datetime.now()\n",
        "#Execution time of the model \n",
        "execution_time = stop1-start1\n",
        "print(\"Execution time is: \", execution_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016c3ccb",
      "metadata": {
        "id": "016c3ccb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}